# -*- coding: utf-8 -*-
"""Heart Disease Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DH5AjdYUHb2RDO2NUPo523azTmICcQWW
"""

!pip install pandas

import pandas as pd

"""# ***Import dataset***"""

from google.colab import files

# Upload the file
uploaded = files.upload()

data = pd.read_csv('heart.csv')

"""# ***Handle missing values***"""

data.isnull().sum() #if there's any values are missing or not

"""# ***Handle Duplicate Values***"""

data_dup = data.duplicated().any() #check duplicate values

data_dup #dataset contains some duplicate values

data = data.drop_duplicates()

data_dup = data.duplicated().any() #drop duplicates values

data_dup

"""# ***Data Processing***"""

cate_val = []   #categorical columns
cont_val = []   #numerical columns
for column in data.columns:
    if data[column].nunique() <=10:
        cate_val.append(column)    #if less than 20 then particular columns are categorical columns
    else:
        cont_val.append(column)   #otherwise continuous columns

cate_val   #all the categorical columns

cont_val  #all the continuous columns

"""# ***Encoding Categorical Data***"""

data['cp'].unique()   #how many unique datas

cate_val.remove('sex')
cate_val.remove('target')
data = pd.get_dummies(data,columns = cate_val, drop_first=True)

data.head()

"""# ***Feature Scaling***"""

from sklearn.preprocessing import StandardScaler #for feature scaling

st = StandardScaler()
data[cont_val] = st.fit_transform(data[cont_val]) #data & numerical colum

data.head()

"""# ***Splitting the dataset into the training Set & test set***"""

X = data.drop('target', axis=1)

X  #independent variable

y = data['target']
y

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state = 45)

X_train

y_test

y_train

y_test

"""# **Algorithms**

# ***Logistic Regression***
"""

data.head()

from sklearn.linear_model import LogisticRegression

log = LogisticRegression()
log.fit(X_train, y_train)  #train logistic regression

y_pred1 = log.predict(X_test)  #different prediction

from sklearn.metrics import accuracy_score

accuracy_score(y_test, y_pred1)   #accuracy rate

"""85% Accuracy

# ***SVC (Support Vector Classifier)***
"""

from sklearn import svm

svm = svm.SVC()

svm.fit(X_train, y_train)

y_pred2 = svm.predict(X_test)  #new predicted value

accuracy_score(y_test, y_pred2)

"""82% Accuracy

# ***K-nearest Neighbors Classifier***
"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier()  #ctreate instance

knn.fit(X_train, y_train)

y_pred3 = knn.predict(X_test) #prediction on unseen samples

accuracy_score(y_test,y_pred3)

"""84% Accuracy"""

score = []

for i in range(1, 45):
    knn=KNeighborsClassifier(n_neighbors = i)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    score.append(accuracy_score(y_test, y_pred))

score

import matplotlib.pyplot as plt

plt.plot(score)
plt.xlabel("i Value")
plt.ylabel("Acc")
plt.show()

knn = KNeighborsClassifier(n_neighbors = 2)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)
accuracy_score(y_test, y_pred)

"""82% Accuracy

### Non-Linear ML Algorithms
"""

data = pd.read_csv('heart.csv')

data = data.drop_duplicates()  #remove duplicates values

data.shape

X = data.drop('target', axis=1)
y = data['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 45)

"""# ***Decision Tree Classifier***"""

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier()

dt.fit(X_train, y_train)

y_pred4 = dt.predict(X_test)

accuracy_score(y_test, y_pred4)

"""70% accuracy

# ***Random Forest Classifier***
"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()  #instance od classifier

rf.fit(X_train, y_train)

y_pred5 = rf.predict(X_test) #predicted on unseen

accuracy_score(y_test, y_pred5)

"""84% Accuracy

# ***Gradient Boosting Classifier***
"""

from sklearn.ensemble import GradientBoostingClassifier

gbc = GradientBoostingClassifier()

gbc.fit(X_train, y_train)

y_pred6 = gbc.predict(X_test)

accuracy_score(y_test, y_pred6)

"""74% Accuracy

# ***Naive Bayes Classifier***
"""

from sklearn.naive_bayes import GaussianNB

nv = GaussianNB()

nv.fit(X_train, y_train)

y_pred7 = nv.predict(X_test)

accuracy_score(y_test, y_pred7)

"""84% Accuracy

# ***Final Data of all Algorithms***
"""

final_data = pd.DataFrame({
    'Models': ['LR', 'SVM', 'KNN', 'DT', 'RF', 'GB', 'NB'],
    'ACC': [
        accuracy_score(y_test, y_pred1) * 100,
        accuracy_score(y_test, y_pred2) * 100,
        accuracy_score(y_test, y_pred3) * 100,
        accuracy_score(y_test, y_pred4) * 100,
        accuracy_score(y_test, y_pred5) * 100,
        accuracy_score(y_test, y_pred6) * 100,
        accuracy_score(y_test, y_pred7) * 100
    ]
})

final_data

import seaborn as sns

sns.barplot(x=final_data['Models'], y=final_data['ACC'])

"""# **Best Model: Logistic Regression**

**Let's train Logistic Regression (85% Accuracy) on our entire dataset**
"""

X = data.drop('target', axis=1)
y = data['target']

X.shape

from sklearn.ensemble import RandomForestClassifier

log = LogisticRegression()
log.fit(X, y)

"""# ***Prediction on New Data***"""

import pandas as pd

new_data = pd.DataFrame (
  {
    'age':52,
    'sex':1,
    'cp':0,
    'trestbps':125,
    'chol':212,
    'fbs':0,
    'restecg':1,
    'thalach':168,
    'exang':0,
    'oldpeak':1.0,
    'slope':2,
    'ca':2,
    'thal':3,
  },
     index=[0])

new_data

p = log.predict(new_data)  #pass dataframe
if p[0] == 0:
    print("No Disease")
else:
    print("Disease")

"""# ***Save Model Using Joblib***"""

import joblib

joblib.dump(rf, 'model_joblib_heart')

model = joblib.load('model_joblib_heart')

model.predict(new_data)  #using this model perform predict

data.tail()

"""### GUI"""

from tkinter import *
import joblib

import joblib
import numpy as np
from sklearn import *
import ipywidgets as widgets
from IPython.display import display

def show_entry_fields(b):
    p1 = int(n1.value)
    p2 = int(n2.value)
    p3 = int(n3.value)
    p4 = int(n4.value)
    p5 = int(n5.value)
    p6 = int(n6.value)
    p7 = int(n7.value)
    p8 = int(n8.value)
    p9 = int(n9.value)
    p10 = float(n10.value)
    p11 = int(n11.value)
    p12 = int(n12.value)
    p13 = int(n13.value)

    model = joblib.load('model_joblib_heart')
    result = model.predict([[p1,p2,p3,p4,p5,p6,p7,p8,p8,p10,p11,p12,p13]])

    if result == 0:
        result_label.value = "No Heart Disease"
    else:
        result_label.value = "Possibility of Heart Disease"

n1 = widgets.IntText(description="Age: ")
n2 = widgets.IntText(description="Male/Female [1/0]: ")
n3 = widgets.IntText(description="CP: ")
n4 = widgets.IntText(description="trestbps: ")
n5 = widgets.IntText(description="chol: ")
n6 = widgets.IntText(description="fbs: ")
n7 = widgets.IntText(description="restecg: ")
n8 = widgets.IntText(description="thalach: ")
n9 = widgets.IntText(description="exang: ")
n10 = widgets.FloatText(description="oldpeak: ")
n11 = widgets.IntText(description="slope: ")
n12 = widgets.IntText(description="ca: ")
n13 = widgets.IntText(description="thal: ")

predict_button = widgets.Button(description = "Predict")
predict_button.on_click(show_entry_fields)

result_label = widgets.Label()

display(n1, n2, n3, n4, n5, n6, n7, n8, n9, n10, n11, n12, n13, predict_button, result_label)